{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z06Wz-qVzcV8"
      },
      "source": [
        "# DengAI: Predicting Disease Spread\n",
        "\n",
        "**Problem description**\n",
        "\n",
        "Our goal is to predict the total_cases label for each (city, year, weekofyear) in the test set. There are two cities, San Juan and Iquitos, with test data for each city spanning 5 and 3 years respectively. You will make one submission that contains predictions for both cities. The data for each city have been concatenated along with a city column indicating the source: sj for San Juan and iq for Iquitos. The test set is a pure future hold-out, meaning the test data are sequential and non-overlapping with any of the training data. Throughout, missing values have been filled as NaNs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbLp_wU50VXE"
      },
      "source": [
        "**Importing libraries**\n",
        "\n",
        "We have used the Keras which is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. We have used it for the deep leraning tasks. Further we have used Matplot Library and Seabornlibrary  for plotting the graphs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a57svVr1TbZ"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMRYk1hj0kkJ"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "The dataset consits following files ::\n",
        "\n",
        "1.   Training Data Features\t\n",
        "The features for the training dataset.\n",
        "2.   Training Data Labels\t\n",
        "The number of dengue cases for each row in the training dataset.\n",
        "3.   Test Data Features\t\n",
        "The features for the testing dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKRUX0CP1ZUO",
        "outputId": "7c5da298-820d-4528-ab02-d545c20ea5e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "dengue_features_train_df = pd.read_csv(\"dengue_features_train.csv\")\n",
        "dengue_features_test_df = pd.read_csv(\"dengue_features_test.csv\")\n",
        "dengue_labels_train_df = pd.read_csv(\"dengue_labels_train.csv\")\n",
        "\n",
        "dengue_features_train_df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9fcca438bcd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdengue_features_train_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dengue_features_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdengue_features_test_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dengue_features_test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdengue_labels_train_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dengue_labels_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdengue_features_train_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dengue_features_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBL6cWZkfvv4"
      },
      "source": [
        "dengue_features_train_df['year'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nO-k6Y54GDR"
      },
      "source": [
        "**Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8s7mYgT5HXS"
      },
      "source": [
        "dengue_features_train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw0DYIPG5LQP"
      },
      "source": [
        "dengue_features_train_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj1sHR3I5OqU"
      },
      "source": [
        "Getting the data types for the columns "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp6RhKfg5RPY"
      },
      "source": [
        "dengue_features_train_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbrQrtrA68rP"
      },
      "source": [
        "**Checking weather the featues has missed values.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axPBNS6a3xPs"
      },
      "source": [
        "dengue_features_train_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUdOB2Am7pbQ"
      },
      "source": [
        "It seems column  `ndvi_ne`  has more missing values .  \n",
        "**Fill the features by the mean**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye8KfT0MAamX"
      },
      "source": [
        "dengue_features_train_df[\"ndvi_ne\"] = dengue_features_train_df[\"ndvi_ne\"].fillna(dengue_features_train_df[\"ndvi_ne\"].mean())\n",
        "dengue_features_train_df[\"ndvi_nw\"] = dengue_features_train_df[\"ndvi_nw\"].fillna(dengue_features_train_df[\"ndvi_nw\"].mean())\n",
        "dengue_features_train_df[\"ndvi_se\"] = dengue_features_train_df[\"ndvi_se\"].fillna(dengue_features_train_df[\"ndvi_se\"].mean())\n",
        "dengue_features_train_df[\"ndvi_sw\"] = dengue_features_train_df[\"ndvi_sw\"].fillna(dengue_features_train_df[\"ndvi_sw\"].mean())\n",
        "dengue_features_train_df[\"precipitation_amt_mm\"] = dengue_features_train_df[\"precipitation_amt_mm\"].fillna(dengue_features_train_df[\"precipitation_amt_mm\"].mean())\n",
        "dengue_features_train_df[\"reanalysis_air_temp_k\"] = dengue_features_train_df[\"reanalysis_air_temp_k\"].fillna(dengue_features_train_df[\"reanalysis_air_temp_k\"].mean())\n",
        "dengue_features_train_df[\"reanalysis_avg_temp_k\"] = dengue_features_train_df[\"reanalysis_avg_temp_k\"].fillna(dengue_features_train_df[\"reanalysis_avg_temp_k\"].mean())\n",
        "dengue_features_train_df[\"reanalysis_dew_point_temp_k\"] = dengue_features_train_df[\"reanalysis_dew_point_temp_k\"].fillna(dengue_features_train_df[\"reanalysis_dew_point_temp_k\"].mean())\n",
        "dengue_features_train_df[\"reanalysis_max_air_temp_k\"] = dengue_features_train_df[\"reanalysis_max_air_temp_k\"].fillna(dengue_features_train_df[\"reanalysis_max_air_temp_k\"].mean())\n",
        "dengue_features_train_df[\"reanalysis_min_air_temp_k\"] = dengue_features_train_df[\"reanalysis_min_air_temp_k\"].fillna(dengue_features_train_df[\"reanalysis_min_air_temp_k\"].mean())\n",
        "dengue_features_train_df[\"reanalysis_precip_amt_kg_per_m2\"] = dengue_features_train_df[\"reanalysis_precip_amt_kg_per_m2\"].fillna(dengue_features_train_df[\"reanalysis_precip_amt_kg_per_m2\"].mean())\n",
        "dengue_features_train_df[\"reanalysis_relative_humidity_percent\"] = dengue_features_train_df[\"reanalysis_relative_humidity_percent\"].fillna(dengue_features_train_df[\"reanalysis_relative_humidity_percent\"].mean())\n",
        "dengue_features_train_df[\"reanalysis_sat_precip_amt_mm\"] = dengue_features_train_df[\"reanalysis_sat_precip_amt_mm\"].fillna(dengue_features_train_df[\"reanalysis_sat_precip_amt_mm\"].mean())\n",
        "dengue_features_train_df[\"reanalysis_specific_humidity_g_per_kg\"] = dengue_features_train_df[\"reanalysis_specific_humidity_g_per_kg\"].fillna(dengue_features_train_df[\"reanalysis_specific_humidity_g_per_kg\"].mean())\n",
        "dengue_features_train_df[\"reanalysis_tdtr_k\"] = dengue_features_train_df[\"reanalysis_tdtr_k\"].fillna(dengue_features_train_df[\"reanalysis_tdtr_k\"].mean())\n",
        "dengue_features_train_df[\"station_avg_temp_c\"] = dengue_features_train_df[\"station_avg_temp_c\"].fillna(dengue_features_train_df[\"station_avg_temp_c\"].mean())\n",
        "dengue_features_train_df[\"station_diur_temp_rng_c\"] = dengue_features_train_df[\"station_diur_temp_rng_c\"].fillna(dengue_features_train_df[\"station_diur_temp_rng_c\"].mean())\n",
        "dengue_features_train_df[\"station_max_temp_c\"] = dengue_features_train_df[\"station_max_temp_c\"].fillna(dengue_features_train_df[\"station_max_temp_c\"].mean())\n",
        "dengue_features_train_df[\"station_min_temp_c\"] = dengue_features_train_df[\"station_min_temp_c\"].fillna(dengue_features_train_df[\"station_min_temp_c\"].mean())\n",
        "dengue_features_train_df[\"station_precip_mm\"] = dengue_features_train_df[\"station_precip_mm\"].fillna(dengue_features_train_df[\"station_precip_mm\"].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIKTWSPoBz2v"
      },
      "source": [
        "**Checking again to verify whetehr there is any null values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qpKuM1r6pSG"
      },
      "source": [
        "dengue_features_train_df.to_csv(\"dengue_features_train_clean.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7QyjYS5A9T-"
      },
      "source": [
        "dengue_features_train_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK9F5_1IB2Wc"
      },
      "source": [
        "dengue_features_train_df['total_cases'] = dengue_labels_train_df['total_cases']\n",
        "dengue_features_train__corr_df=dengue_features_train_df.drop('week_start_date', axis = 1)\n",
        "dengue_features_train__corr_df=dengue_features_train__corr_df.drop('year', axis = 1)\n",
        "dengue_features_train__corr_df=dengue_features_train__corr_df.drop('weekofyear', axis = 1)\n",
        "dengue_features_train__corr_df=dengue_features_train__corr_df.drop('city', axis = 1)\n",
        "dengue_features_train_corr = dengue_features_train__corr_df.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX0bhxbVHQsU"
      },
      "source": [
        "sns.set() \n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title('Correlation Plot of all features')\n",
        "ax = sns.heatmap(dengue_features_train_corr,cmap=\"BuPu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKM4OM8TJgoR"
      },
      "source": [
        "\n",
        "**Observation from the dataset**\n",
        "\n",
        "No variables are exceptionally good at predicting the label (total cases)\n",
        "\n",
        "The first 4 variables (Normalized Difference Vegetation Index) variables appears to be very weakly correlated with the other variables. They do not appear to be very useful in predicting the labels.\n",
        "\n",
        "Most of temperature variables in both datasets appear to be strongly correlated with one another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N29lDfDJHWZk"
      },
      "source": [
        "sns.set(font_scale = 1.0)\n",
        "(abs(dengue_features_train_corr)\n",
        " .total_cases\n",
        " .drop('total_cases')\n",
        " .sort_values()\n",
        " .plot\n",
        " .barh())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR57XBIrLomF"
      },
      "source": [
        "\n",
        "it appears that certain variables feature prominently on both bar charts, suggesting that they may be commmon drivers of dengue cases. For example, specific humidity (in g/kg), dew point temperature (in K)\n",
        ", minimum air temperature (in K) and  minimum air temperature (in C) appear to be relatively strongly correlated with the total_cases label.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CCoCJ8SMAUG"
      },
      "source": [
        "**Splitting into training, cross-validation and testing dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6UdmqM3WHc9"
      },
      "source": [
        "dengue_features_train__corr_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl553qR-VtXJ"
      },
      "source": [
        "X=dengue_features_train_df.iloc[:,4:-1]\n",
        "y=dengue_features_train_df.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS_oiUcIWgn8"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8PZV3FBWyML"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_BgDY3zXQOJ"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn import linear_model as lm\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score \n",
        "from datetime import datetime, timedelta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzRanf4MLy8x"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_X, test_X, train_y, test_y = train_test_split( X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzWKcLEdW2pu"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "train_X = sc.fit_transform(train_X) \n",
        "test_X = sc.fit_transform(test_X) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6cURM4aXB8a"
      },
      "source": [
        "reg_l = lm.LinearRegression()\n",
        "reg_l_fit = reg_l.fit(train_X, train_y)\n",
        "reg_l_pred=reg_l_fit.predict(test_X)\n",
        "MAE_l=mean_absolute_error(test_y, reg_l_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2qywB86XGqf"
      },
      "source": [
        "print (\"MAE :\", MAE_l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQjJLdjzXKbf"
      },
      "source": [
        "ridge001 = lm.Ridge(alpha = 0.01)\n",
        "ridge001_fit = ridge001.fit(train_X, train_y)\n",
        "ridge001_pred=ridge001_fit.predict(test_X)\n",
        "MAE_r001=mean_absolute_error(test_y, ridge001_pred)\n",
        "print (\"MAE :\", MAE_r001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95mW9KSTXhAI"
      },
      "source": [
        "ridge1OO = lm.Ridge(alpha = 100)\n",
        "ridge100_fit = ridge1OO.fit(train_X, train_y)\n",
        "ridge100_pred=ridge100_fit.predict(test_X)\n",
        "MAE_r1OO=mean_absolute_error(test_y, ridge100_pred)\n",
        "print (\"MAE :\", MAE_r1OO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lSXG8qmXlTK"
      },
      "source": [
        "test_X= dengue_features_test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng5mc-aYYN5j"
      },
      "source": [
        "test_X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIdFR-jMYW9x"
      },
      "source": [
        "test_X=test_X.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEymEmTb7F_V"
      },
      "source": [
        "test_X.to_csv(\"dengue_features_test_clean.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m5n8IqtYbMc"
      },
      "source": [
        "test_X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUlaYyUrYdtU"
      },
      "source": [
        "test_X.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu1YlNVAYfRY"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "test_X = sc.fit_transform(test_X) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN575dumYj75"
      },
      "source": [
        "test_X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWbiQg32YlTK"
      },
      "source": [
        "predict=ridge001.predict(test_X)\n",
        "type(predict)\n",
        "len(predict)\n",
        "y = np.array(np.round(predict), dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLoTVNFnE4x0"
      },
      "source": [
        "dengue_labels_train_df = pd.read_csv(\"dengue_labels_train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSACzZpyEweX"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHSfgZboY1Qz"
      },
      "source": [
        "pred_y = pd.DataFrame(y, columns=[\"total_cases\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUiwhIvJY4GM"
      },
      "source": [
        "Submission_Deng_AI = pd.DataFrame()\n",
        "Submission_Deng_AI[\"city\"] = dengue_features_test_df[\"city\"]\n",
        "Submission_Deng_AI[\"year\"]=dengue_features_test_df[\"year\"]\n",
        "Submission_Deng_AI[\"weekofyear\"]=dengue_features_test_df[\"weekofyear\"]\n",
        "Submission_Deng_AI[\"total_cases\"] =pred_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGeqBQUfFGUn"
      },
      "source": [
        "sub_df = pd.read_csv(\"submission_format - submission_format.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrM12NxgZCRV"
      },
      "source": [
        "y=sub_df['total_cases']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXjBSUaUFsTc"
      },
      "source": [
        "y = np.array(np.round(y), dtype=int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3w-xKQbFwbF"
      },
      "source": [
        "sub_df['total_cases']=y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d07KOw8lF0Yz"
      },
      "source": [
        "sub_df.to_csv(\"sbclean.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhUL9aNBckfP"
      },
      "source": [
        "**Using other Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHgoKBvibYjM"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.initializers import glorot_uniform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntNVO1BVZG-s"
      },
      "source": [
        "def LSTMmodel(input_shape):\n",
        "  \n",
        "    input_ = Input(input_shape, dtype='float32')\n",
        "    # Be careful, the returned output should be a batch of sequences.\n",
        "    X = LSTM(32, return_sequences=False)(input_)\n",
        "    # Add dropout with a probability of 0.5\n",
        "    X = Dropout(0.5)(X)\n",
        "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
        "    X = Dense(1)(X)\n",
        "    model = Model(inputs=input_, outputs=X)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y0BNcQjbaAy"
      },
      "source": [
        "model = LSTMmodel(X.shape[1])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQLN9o7xbyCR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}